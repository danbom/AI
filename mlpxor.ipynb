{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlpxor.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLstpwEwGzJfewv6JH/rLO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danbom/ai/blob/main/mlpxor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4OB-n3ggFV6"
      },
      "source": [
        "# numpy 라이브러리 사용\n",
        "import numpy as np\n",
        "\n",
        "# input 2개, output 1개, sample 4개\n",
        "num_input = 2\n",
        "num_output = 1\n",
        "num_sample = 4\n",
        "\n",
        "# training sample\n",
        "## 이 Nueral Network의 input X, output Ot\n",
        "## Example : Learning XOR (7) 참고\n",
        "X = np.array([0, 0, 1, 1, 0, 1, 0, 1]).reshape(num_input, num_sample)\n",
        "Ot = np.array([0, 1, 1, 0]).reshape(num_output, num_sample)\n",
        "\n",
        "print(\"input>\\nX = \\n\", X)\n",
        "print(\"\\n\")\n",
        "print(\"output>\\nOt = \\n\", Ot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnsJeA-jik6J"
      },
      "source": [
        "# Layer Weight parameter 초기화 함수 만들기\n",
        "# Example : Learning XOR (4) 참고\n",
        "\n",
        "def init_params(num_input = 2, num_hidden = 2) : \n",
        "\n",
        "    # 첫번째 Layer\n",
        "    ## 랜덤하게 초기화\n",
        "    W1 = np.random.rand(num_hidden, num_input)\n",
        "    ## bias도 똑같이 랜덤하게 초기화\n",
        "    B1 = np.random.rand(num_hidden, 1)\n",
        "\n",
        "    # 두번째 Layer\n",
        "    W2 = np.random.rand(num_output, num_hidden)\n",
        "    B2 = np.random.rand(num_output, 1)\n",
        "\n",
        "    return W1, B1, W2, B2\n",
        "\n",
        "# 실행\n",
        "W1, B1, W2, B2 = init_params()\n",
        "print(\"Layer 1 >\\nW1 =\\n\",W1, \"\\nB1 =\\n\", B1, \"\\n\\nLayer 2 >\\nW2 =\\n\", W2, \"\\nB2 =\\n\", B2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqwm3SgAk4aJ"
      },
      "source": [
        "# Weight 행렬과 input을 곱해주는 함수 만들기\n",
        "## 'weight' x 'input' + 'bias'\n",
        "def wxpb(W, X, B) :\n",
        "    return np.dot(W, X) + B\n",
        "\n",
        "# activation function \n",
        "def sigmoid(x) :\n",
        "    return 1./(1+np.exp(-1*x))\n",
        "\n",
        "# 실행\n",
        "## 첫번째 Layer\n",
        "Z1 = wxpb(W1, X, B1)\n",
        "## output ( Example(4)에서 Hidden Layer )\n",
        "Y = sigmoid(Z1)\n",
        "## 두번째 Layer\n",
        "Z2 = wxpb(W2, Y, B2)\n",
        "## 최종 output\n",
        "O = sigmoid(Z2)\n",
        "\n",
        "# 출력\n",
        "print(\"Y =\\n\", Y)\n",
        "print(\"O =\\n\", O)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nTZbvi80hJV"
      },
      "source": [
        "# Loss_function 정의 : logistic regression 식 사용\n",
        "def loss_func(O, Ot) :\n",
        "    return 1./num_sample * np.sum(-1*(Ot * np.log(O) + (1-Ot)*np.log(1-O)))\n",
        "\n",
        "loss = loss_func(O, Ot)\n",
        "print(\"Loss =\\n\", loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aKVTNxE1v0M"
      },
      "source": [
        "# forward propagation\n",
        "def forward(W1, B1, W2, B2) :\n",
        "    # 첫번째 Layer\n",
        "    Z1 = wxpb(W1, X, B1)\n",
        "    Y = sigmoid(Z1)\n",
        "    # 두번째 Layer\n",
        "    Z2 = wxpb(W2, Y, B2)\n",
        "    O = sigmoid(Z2)\n",
        "    # loss\n",
        "    loss = loss_func(O, Ot)\n",
        "    # return\n",
        "    return Z1, Y, Z2, O, loss\n",
        "\n",
        "# back propagation : Backpropagation in DNN (2) 참고\n",
        "def backprop(W1, B1, W2, B2, Z1, Y, Z2, O, Ot) :\n",
        "    # 두번째 레이어부터(뒤부터)\n",
        "    dZ2 = np.multiply((O-Ot), 1)\n",
        "    dW2 = np.dot(dZ2, Y.T)\n",
        "    dB2 = 1. / 4. * np.sum(dZ2, axis = 1, keepdims=True)\n",
        "    dY = np.dot(W2.T, dZ2)\n",
        "    # 첫번째 레이어\n",
        "    dZ1 = np.multiply(dY, Y*(1-Y))\n",
        "    dW1 = np.dot(dZ1, X.T)\n",
        "    dB1 = 1. / 4. * np.sum(dZ1, axis = 1, keepdims=True)\n",
        "    \n",
        "    return dW1, dB1, dW2, dB2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VThLx3wT2SCE"
      },
      "source": [
        "# train 함수 정의\n",
        "## lr = learning rate\n",
        "## loss_trace : training iteration 을 지나감에 따라 변하는 loss 를 trace 하기위해 필요한 array 변수\n",
        "## return 에서 loss 는 iteration 이 모두 끝난 후 최종 loss\n",
        "## return 에서 O 는 최종 output\n",
        "def train(W1, B1, W2, B2, lr = 0.1, iteration = 1000) :\n",
        "\n",
        "    loss_trace = []\n",
        "    \n",
        "    for iter in range(iteration) :\n",
        "\n",
        "        # Training / Inference 참고\n",
        "        ## Forward propagation\n",
        "        Z1, Y, Z2, O, loss = forward(W1, B1, W2, B2)\n",
        "        ## Backpropagation\n",
        "        dW1, dB1, dW2, dB2 = backprop(W1, B1, W2, B2, Z1, Y, Z2, O, Ot)\n",
        "        ## Update Weights/Biases\n",
        "        W1 = W1 - lr * dW1\n",
        "        B1 = B1 - lr * dB1\n",
        "        W2 = W2 - lr * dW2\n",
        "        B2 = B2 - lr * dB2\n",
        "\n",
        "        loss_trace.append(loss)\n",
        "\n",
        "    return W1, B1, W2, B2, loss_trace, loss, O"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSHmPdlo7mEc"
      },
      "source": [
        "# 실제 함수 동작시키기\n",
        "## initialize\n",
        "W1, B1, W2, B2 = init_params()\n",
        "## 동작\n",
        "W1, B1, W2, B2, loss_trace, loss, O = train(W1, B1, W2, B2, 0.1, 50000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj8SHtOj75Gc"
      },
      "source": [
        "# loss_trace 그래프\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loss_trace)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iterations')\n",
        "plt.show()\n",
        "print(\"최종 output =\\n\", O)\n",
        "print(\"최종 loss =\\n\", loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-nLhZedeVYT"
      },
      "source": [
        "for i in range(5) :\n",
        "    ## initialize\n",
        "    W1, B1, W2, B2 = init_params()\n",
        "    ## 동작\n",
        "    W1, B1, W2, B2, loss_trace, loss, O = train(W1, B1, W2, B2, 0.1, 4000)\n",
        "    print(i+1, \"번째 최종 loss =\\n\", loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvQ4PoxZe89k"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_train(W1, B1, W2, B2, lr, iteration) :\n",
        "\n",
        "    loss_trace = []\n",
        "    flag = 0\n",
        "    for iter in range(iteration) :\n",
        "\n",
        "        # Training / Inference 참고\n",
        "        ## Forward propagation\n",
        "        Z1, Y, Z2, O, loss = forward(W1, B1, W2, B2)\n",
        "        ## Backpropagation\n",
        "        dW1, dB1, dW2, dB2 = backprop(W1, B1, W2, B2, Z1, Y, Z2, O, Ot)\n",
        "        ## Update Weights/Biases\n",
        "        W1 = W1 - lr * dW1\n",
        "        B1 = B1 - lr * dB1\n",
        "        W2 = W2 - lr * dW2\n",
        "        B2 = B2 - lr * dB2\n",
        "\n",
        "        loss_trace.append(loss)\n",
        "\n",
        "        if loss < 0.02 and flag == 0:\n",
        "            print(\"Learning rate가 \", lr, \"인 경우 >\")\n",
        "            print(\"0.02 미만에 도달하는 iteration 횟수 : \", iter)\n",
        "            print(\"이 때의 loss 값 : \", loss, \"\\n\")\n",
        "            flag=1\n",
        "            break\n",
        "\n",
        "    return W1, B1, W2, B2, loss_trace, loss, O\n",
        "    \n",
        "# learning rate = 1\n",
        "\n",
        "W1, B1, W2, B2 = init_params()\n",
        "fixW1, fixB2, fixW2, fixB2 = W1, B1, W2, B2\n",
        "W1, B1, W2, B2, loss_trace, loss, O = test_train(W1, B1, W2, B2, 1, 100000)\n",
        "plt.figure(figsize=(12,3))\n",
        "plt.plot(loss_trace)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iterations')\n",
        "plt.show()\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# learning rate = 0.5\n",
        "\n",
        "W1, B1, W2, B2 = init_params()\n",
        "fixW1, fixB2, fixW2, fixB2 = W1, B1, W2, B2\n",
        "W1, B1, W2, B2, loss_trace, loss, O = test_train(W1, B1, W2, B2, 0.5, 100000)\n",
        "plt.figure(figsize=(12,3))\n",
        "plt.plot(loss_trace)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iterations')\n",
        "plt.show()\n",
        "print(\"\\n\")\n",
        "\n",
        "# learning rate = 0.1\n",
        "\n",
        "W1, B1, W2, B2, loss_trace, loss, O = test_train(fixW1, fixB2, fixW2, fixB2, 0.1, 100000)\n",
        "plt.figure(figsize=(12,3))\n",
        "plt.plot(loss_trace)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iterations')\n",
        "plt.show()\n",
        "print(\"\\n\")\n",
        "\n",
        "# learning rate = 0.01\n",
        "\n",
        "W1, B1, W2, B2, loss_trace, loss, O = test_train(fixW1, fixB2, fixW2, fixB2, 0.01, 100000)\n",
        "plt.figure(figsize=(12,3))\n",
        "plt.plot(loss_trace)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iterations')\n",
        "plt.show()\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# learning rate = 0.0001\n",
        "\n",
        "W1, B1, W2, B2 = init_params()\n",
        "fixW1, fixB2, fixW2, fixB2 = W1, B1, W2, B2\n",
        "W1, B1, W2, B2, loss_trace, loss, O = test_train(W1, B1, W2, B2, 0.0001, 100000)\n",
        "plt.figure(figsize=(12,3))\n",
        "plt.plot(loss_trace)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iterations')\n",
        "plt.show()\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olWHqGGrza2t"
      },
      "source": [
        "# weight, bias 모두 0으로 초기화되는 경우\n",
        "## initialize\n",
        "def test_init_params(num_input = 2, num_hidden = 2) : \n",
        "\n",
        "    # 첫번째 Layer\n",
        "    ## 0으로 초기화\n",
        "    W1 = np.zeros((num_hidden, num_input))\n",
        "    ## bias도 똑같이 0으로 초기화\n",
        "    B1 = np.zeros((num_hidden, 1))\n",
        "\n",
        "    # 두번째 Layer\n",
        "    W2 = np.zeros((num_output, num_hidden))\n",
        "    B2 = np.zeros((num_output, 1))\n",
        "\n",
        "    return W1, B1, W2, B2\n",
        "\n",
        "## 동작\n",
        "W1, B1, W2, B2 = test_init_params()\n",
        "W1, B1, W2, B2, loss_trace, loss, O = train(W1, B1, W2, B2, 0.1, 4000)\n",
        "\n",
        "# loss_trace 그래프\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loss_trace)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iterations')\n",
        "plt.show()\n",
        "print(\"최종 output =\\n\", O)\n",
        "print(\"최종 loss =\\n\", loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmI8mbPw_-Hh"
      },
      "source": [
        "for i in range(5) :\n",
        "    ## initialize\n",
        "    W1, B1, W2, B2 = test_init_params()\n",
        "    ## 동작\n",
        "    W1, B1, W2, B2, loss_trace, loss, O = train(W1, B1, W2, B2, 0.1, 4000)\n",
        "    print(i+1, \"번째 최종 loss =\\n\", loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}